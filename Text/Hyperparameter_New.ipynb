{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70ab58ec",
   "metadata": {
    "id": "70ab58ec"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55e38fb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "55e38fb2",
    "outputId": "a774245a-6330-457d-84a4-24487c758126"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  cEXT  cNEU  cAGR  cCON  \\\n",
       "0  Well, right now I just woke up from a mid-day ...     0     1     1     0   \n",
       "1  Well, here we go with the stream of consciousn...     0     0     1     0   \n",
       "2  An open keyboard and buttons to push. The thin...     0     1     0     1   \n",
       "3  I can't believe it!  It's really happening!  M...     1     0     1     1   \n",
       "4  Well, here I go with the good old stream of co...     1     0     1     0   \n",
       "\n",
       "   cOPN  \n",
       "0     1  \n",
       "1     0  \n",
       "2     1  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essays = pd.read_csv('data/training/essays.csv', encoding='cp1252', delimiter=',', quotechar='\"')\n",
    "\n",
    "# for every essay, we replace the personalitiy categories \n",
    "# of the essay wich are \"y\" and \"n\" with \"1\" and \"0\" \n",
    "for e in df_essays.columns[2:7]:\n",
    "    df_essays[e] = df_essays[e].replace('n', '0')\n",
    "    df_essays[e] = df_essays[e].replace('y', '1')\n",
    "    # not sure if we need this line: furter investigation possible:\n",
    "    df_essays[e] = pd.to_numeric(df_essays[e])\n",
    "\n",
    "df_essays = df_essays[[\"TEXT\", \"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]]\n",
    "df_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "156c0879",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "156c0879",
    "outputId": "d7c269ba-2904-4eb5-b9c7-4cd50074a97d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = pd.read_csv('data/training/mbti_1.csv',  skiprows=0 )\n",
    "df_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cc7c393",
   "metadata": {
    "id": "0cc7c393"
   },
   "outputs": [],
   "source": [
    "def mbti_to_big5(mbti):\n",
    "    mbti = mbti.lower()\n",
    "    cEXT, cNEU, cAGR, cCON, cOPN = 0,np.NaN,0,0,0\n",
    "    \n",
    "    ## IN MBTI, extrovert or introvert\n",
    "    ## correlates with Extroversion\n",
    "    if mbti[0] == \"i\":\n",
    "        cEXT = 0\n",
    "    elif mbti[0] == \"e\":\n",
    "        cEXT = 1\n",
    "        \n",
    "    ## IN MBTI, Feeler or Thinker\n",
    "    ## correlates with Agrreableness\n",
    "    if mbti[2] == \"t\":\n",
    "        cAGR = 0\n",
    "    elif mbti[2] == \"f\":\n",
    "        cAGR = 1\n",
    "\n",
    "    ## IN MBTI, Judger or Perceiver\n",
    "    ## correlates with Conscientiousness\n",
    "    if mbti[3] == \"p\":\n",
    "        cCON = 0\n",
    "    elif mbti[3] == \"j\":\n",
    "        cCON = 1\n",
    "        \n",
    "    ## IN MBTI, Intuition or Sensing \n",
    "    ## correlates with Openness\n",
    "    if mbti[1] == \"n\":\n",
    "        cOPN = 1\n",
    "    elif mbti[1] == \"s\":\n",
    "        cOPN = 0   \n",
    "        \n",
    "    return cEXT, cNEU, cAGR, cCON, cOPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07d80055",
   "metadata": {
    "id": "07d80055"
   },
   "outputs": [],
   "source": [
    "# simply put every row of our read dataframe into a list of \n",
    "# the object \"Essay\"\n",
    "# remove data from list substract\n",
    "def create_essays(df, subtract=None):\n",
    "    essays = []\n",
    "    for index, row in df.iterrows():\n",
    "        essays.append(essay.Essay(row.TEXT, row.cEXT, row.cNEU, row.cAGR, row.cCON, row.cOPN))  \n",
    "\n",
    "    # remove scentences which do not contain emotionally charged words \n",
    "    # from the emotional lexicon\n",
    "    if subtract != None:\n",
    "        for x in essays:\n",
    "            x.filtered_text = remove_unemotional_scentences(emotional_words, x.clean_text)\n",
    "\n",
    "    return essays\n",
    "\n",
    "def remove_unemotional_scentences(emotional_words, text_as_one_string):\n",
    "    reduced_s = \"\"\n",
    "    scentences = re.split('(?<=[.!?]) +', text_as_one_string)\n",
    "    for s in scentences:\n",
    "        if any(e in s for e in emotional_words):\n",
    "            reduced_s = reduced_s + s + \" \"\n",
    "        else:\n",
    "            pass\n",
    "    return reduced_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "363ae30d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "363ae30d",
    "outputId": "155cc542-587a-4860-8569-786a64e4ef0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, nan, 0, 1, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_to_big5(df_kaggle['type'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb151bc",
   "metadata": {
    "id": "1fb151bc"
   },
   "outputs": [],
   "source": [
    "df_kaggle[\"cEXT\"] =   df_kaggle.apply(lambda x: mbti_to_big5(x.type)[0], 1)\n",
    "df_kaggle[\"cNEU\"] =   df_kaggle.apply(lambda x: mbti_to_big5(x.type)[1], 1)\n",
    "df_kaggle[\"cAGR\"] =   df_kaggle.apply(lambda x: mbti_to_big5(x.type)[2], 1)\n",
    "df_kaggle[\"cCON\"] =   df_kaggle.apply(lambda x: mbti_to_big5(x.type)[3], 1)\n",
    "df_kaggle[\"cOPN\"] =   df_kaggle.apply(lambda x: mbti_to_big5(x.type)[4], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3409dcfd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "3409dcfd",
    "outputId": "f53a8613-d762-48e1-c9aa-23902aa67c26"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  cEXT  cNEU  \\\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...     0   NaN   \n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...     1   NaN   \n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...     0   NaN   \n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...     0   NaN   \n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...     1   NaN   \n",
       "...    ...                                                ...   ...   ...   \n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...     0   NaN   \n",
       "8671  ENFP  'So...if this thread already exists someplace ...     1   NaN   \n",
       "8672  INTP  'So many questions when i do these things.  I ...     0   NaN   \n",
       "8673  INFP  'I am very conflicted right now when it comes ...     0   NaN   \n",
       "8674  INFP  'It has been too long since I have been on per...     0   NaN   \n",
       "\n",
       "      cAGR  cCON  cOPN  \n",
       "0        1     1     1  \n",
       "1        0     0     1  \n",
       "2        0     0     1  \n",
       "3        0     1     1  \n",
       "4        0     1     1  \n",
       "...    ...   ...   ...  \n",
       "8670     1     0     0  \n",
       "8671     1     0     1  \n",
       "8672     0     0     1  \n",
       "8673     1     0     1  \n",
       "8674     1     0     1  \n",
       "\n",
       "[8675 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97d70d5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "97d70d5a",
    "outputId": "0a700be1-1437-44c2-d4f9-155e63138a13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-fd0fa10ecf1d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_kaggle[\"TEXT\"] = df_kaggle.apply(lambda x: x.TEXT.replace(\"|||\", \" \")[:], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw ht...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'You're fired. That's another silly misconcept...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  cEXT  cNEU  cAGR  cCON  \\\n",
       "0  'http://www.youtube.com/watch?v=qsXHcwe3krw ht...     0   NaN     1     1   \n",
       "1  'I'm finding the lack of me in these posts ver...     1   NaN     0     0   \n",
       "2  'Good one  _____   https://www.youtube.com/wat...     0   NaN     0     0   \n",
       "3  'Dear INTP,   I enjoyed our conversation the o...     0   NaN     0     1   \n",
       "4  'You're fired. That's another silly misconcept...     1   NaN     0     1   \n",
       "\n",
       "   cOPN  \n",
       "0     1  \n",
       "1     1  \n",
       "2     1  \n",
       "3     1  \n",
       "4     1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kaggle = df_kaggle[[\"posts\", \"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]]\n",
    "df_kaggle.columns = [\"TEXT\", \"cEXT\", \"cNEU\", \"cAGR\", \"cCON\", \"cOPN\"]\n",
    "# remove som fancy ||| things\n",
    "df_kaggle[\"TEXT\"] = df_kaggle.apply(lambda x: x.TEXT.replace(\"|||\", \" \")[:], 1)\n",
    "\n",
    "df_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8838ba16",
   "metadata": {
    "id": "8838ba16"
   },
   "outputs": [],
   "source": [
    "## Load Emotional Lexicon to substract from data\n",
    "\n",
    "# also from \"Emotional_Lexicon.csv\" we read in the data, which is a list of words and \n",
    "# has several categories of emotions. \n",
    "# anger - anticipation - disgust - fear - joy - negative - positive \n",
    "# - sadness - surprise - trust - Charged\n",
    "df_lexicon = pd.read_csv('data/training/Emotion_Lexicon.csv', index_col=0)\n",
    "\n",
    "\n",
    "# some of the words have no emotional category, \n",
    "# so let's remove them as they have no use to us.\n",
    "# can be improved by not even loading them when all columns are 0. maybe later.\n",
    "df_lexicon = df_lexicon[(df_lexicon.T != 0).any()]\n",
    "emotional_words = df_lexicon.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b0916",
   "metadata": {
    "id": "552b0916"
   },
   "source": [
    "### Create data frame MBTI AND BIG5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fdde7d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fdde7d8",
    "outputId": "25a8431f-8f80-49db-dca1-9728bdeb177d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved entries:  11142\n"
     ]
    }
   ],
   "source": [
    "# concatinate the dataframes:\n",
    "frames  = [df_essays, df_kaggle]\n",
    "essays_kaggle = pd.concat(frames, sort=False)\n",
    "essays_kaggle.reset_index(drop=True)\n",
    "\n",
    "# preprocess data by converting into OBJECT essay and save with pickle and removing non emotional scentences\n",
    "#essays_kaggle = create_essays(essays_kaggle, emotional_words)\n",
    "#pickle.dump(essays_kaggle, open(\"essays/essays11142.p\", \"wb\"))\n",
    "print(\"saved entries: \", len(essays_kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9ebdec1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "a9ebdec1",
    "outputId": "f54a4396-f6bd-4d64-c192-0019c7811611"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908 I...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11142 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   TEXT  cEXT  cNEU  cAGR  \\\n",
       "0     Well, right now I just woke up from a mid-day ...     0   1.0     1   \n",
       "1     Well, here we go with the stream of consciousn...     0   0.0     1   \n",
       "2     An open keyboard and buttons to push. The thin...     0   1.0     0   \n",
       "3     I can't believe it!  It's really happening!  M...     1   0.0     1   \n",
       "4     Well, here I go with the good old stream of co...     1   0.0     1   \n",
       "...                                                 ...   ...   ...   ...   \n",
       "8670  'https://www.youtube.com/watch?v=t8edHB_h908 I...     0   NaN     1   \n",
       "8671  'So...if this thread already exists someplace ...     1   NaN     1   \n",
       "8672  'So many questions when i do these things.  I ...     0   NaN     0   \n",
       "8673  'I am very conflicted right now when it comes ...     0   NaN     1   \n",
       "8674  'It has been too long since I have been on per...     0   NaN     1   \n",
       "\n",
       "      cCON  cOPN  \n",
       "0        0     1  \n",
       "1        0     0  \n",
       "2        1     1  \n",
       "3        1     0  \n",
       "4        0     1  \n",
       "...    ...   ...  \n",
       "8670     0     0  \n",
       "8671     0     1  \n",
       "8672     0     1  \n",
       "8673     0     1  \n",
       "8674     0     1  \n",
       "\n",
       "[11142 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ad43c0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ad43c0f",
    "outputId": "79e340cf-03fb-42bc-deae-1c220a3583b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Piyush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Piyush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def preprocess(text):\n",
    "    corpus = []\n",
    "    \n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>2 and token not in stop_words:\n",
    "            corpus.append(token)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5748920",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "e5748920",
    "outputId": "d54e1770-65eb-4972-aa8d-9a834c843dd1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>clean</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, right now I just woke up from a mid-day ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[right, woke, mid, day, nap, sort, weird, move...</td>\n",
       "      <td>right woke mid day nap sort weird moved texas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well, here we go with the stream of consciousn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[stream, consciousness, essay, things, like, h...</td>\n",
       "      <td>stream consciousness essay things like high sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An open keyboard and buttons to push. The thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[open, keyboard, buttons, push, thing, finally...</td>\n",
       "      <td>open keyboard buttons push thing finally worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can't believe it!  It's really happening!  M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[believe, happening, pulse, racing, like, mad,...</td>\n",
       "      <td>believe happening pulse racing like mad like f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, here I go with the good old stream of co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, old, stream, consciousness, assignment,...</td>\n",
       "      <td>good old stream consciousness assignment feel ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  cEXT  cNEU  cAGR  cCON  \\\n",
       "0  Well, right now I just woke up from a mid-day ...     0   1.0     1     0   \n",
       "1  Well, here we go with the stream of consciousn...     0   0.0     1     0   \n",
       "2  An open keyboard and buttons to push. The thin...     0   1.0     0     1   \n",
       "3  I can't believe it!  It's really happening!  M...     1   0.0     1     1   \n",
       "4  Well, here I go with the good old stream of co...     1   0.0     1     0   \n",
       "\n",
       "   cOPN                                              clean  \\\n",
       "0     1  [right, woke, mid, day, nap, sort, weird, move...   \n",
       "1     0  [stream, consciousness, essay, things, like, h...   \n",
       "2     1  [open, keyboard, buttons, push, thing, finally...   \n",
       "3     0  [believe, happening, pulse, racing, like, mad,...   \n",
       "4     1  [good, old, stream, consciousness, assignment,...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  right woke mid day nap sort weird moved texas ...  \n",
       "1  stream consciousness essay things like high sc...  \n",
       "2  open keyboard buttons push thing finally worke...  \n",
       "3  believe happening pulse racing like mad like f...  \n",
       "4  good old stream consciousness assignment feel ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essays_kaggle['clean'] = essays_kaggle['TEXT'].apply(preprocess)\n",
    "essays_kaggle['clean_text'] = essays_kaggle['clean'].apply(lambda x:\" \".join(x))\n",
    "essays_kaggle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65fbd30d",
   "metadata": {
    "id": "65fbd30d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "training, test = train_test_split(essays_kaggle, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31667844",
   "metadata": {
    "id": "31667844"
   },
   "outputs": [],
   "source": [
    "train_x = training.clean_text\n",
    "\n",
    "train_y_cEXT = training['cEXT']\n",
    "train_y_cNEU = training['cNEU']\n",
    "train_y_cAGR = training['cAGR']\n",
    "train_y_cCON = training['cCON']\n",
    "train_y_cOPN = training['cOPN']\n",
    "\n",
    "\n",
    "test_x = test.clean_text\n",
    "\n",
    "test_y_cEXT = test['cEXT']\n",
    "test_y_cNEU = test['cNEU']\n",
    "test_y_cAGR = test['cAGR']\n",
    "test_y_cCON = test['cCON']\n",
    "test_y_cOPN = test['cOPN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ee782e9",
   "metadata": {
    "id": "5ee782e9"
   },
   "outputs": [],
   "source": [
    "## BAG OF WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# create vectors from our words\n",
    "train_x_vectors = bow_vectorizer.fit_transform(train_x)\n",
    "test_x_vectors = bow_vectorizer.transform(test_x)\n",
    "# # now that's a big thing :-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9bdf02d",
   "metadata": {
    "id": "d9bdf02d"
   },
   "outputs": [],
   "source": [
    "## TFIDF VECTORIZER\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "train_x_vectors_tf = cv.fit_transform(train_x)\n",
    "test_x_vectors_tf = cv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e5c06f3",
   "metadata": {
    "id": "4e5c06f3"
   },
   "outputs": [],
   "source": [
    "# for evaluation save some data for later:\n",
    "evaluation = []\n",
    "evaluation_tf = []\n",
    "data = len(essays_kaggle)\n",
    "vec_name = \"MBTI\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10211304",
   "metadata": {
    "id": "10211304"
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2920dca7",
   "metadata": {
    "id": "2920dca7"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b36486",
   "metadata": {
    "id": "b2b36486"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C':[100,1000], 'gamma':[0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6a8e2",
   "metadata": {
    "id": "59d6a8e2"
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac58fb",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "dcac58fb",
    "outputId": "e128312d-3084-4f0e-dd85-daa7b4a9ec8e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=100, gamma=0.001, total= 3.2min\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............................... C=100, gamma=0.001, total= 3.3min\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total= 3.3min\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total= 3.2min\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total= 3.3min\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total= 2.7min\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total= 2.7min\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total= 3.6min\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total= 2.7min\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total= 2.7min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total= 3.2min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total= 3.3min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total= 3.3min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total= 3.2min\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total= 3.3min\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total= 3.5min\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total= 2.7min\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total= 3.6min\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total= 2.7min\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed: 62.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [100, 1000], 'gamma': [0.001, 0.0001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(train_x_vectors, train_y_cEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee54d074",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ee54d074",
    "outputId": "f38a2054-71a2-463a-fdf9-af66799bb82f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.001}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "406d872c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "406d872c",
    "outputId": "b137ff02-34dc-407f-8a11-ac4c207899db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ru0qMeonJWT9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ru0qMeonJWT9",
    "outputId": "6fbe5fef-0932-4961-ff3c-3af554ed7a89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886944818304172"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(test_x_vectors, test_y_cEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf7143e",
   "metadata": {
    "id": "1cf7143e",
    "outputId": "9ca379cc-06c4-4cc1-b277-437f8179f403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Extraversion cEXT using SVM...\n",
      "cEXT score:  0.7900403768506057\n",
      "training Neuroticism cNEU using SVM...\n",
      "with this data not available (MBTI only 4 dimensions)\n",
      "training Agreeableness cAGR using using SVM...\n",
      "cAGR score:  0.7581875280394796\n",
      "training Conscientiousness cCON using SVM...\n",
      "cCON score:  0.7222969941677883\n",
      "training Openness to Experience cOPN using SVM...\n",
      "cOPN score:  0.8115746971736204\n"
     ]
    }
   ],
   "source": [
    "## SVM\n",
    "\n",
    "from sklearn import svm\n",
    "name = \"svm\"\n",
    "\n",
    "print(\"training Extraversion cEXT using SVM...\")\n",
    "clf_svm_cEXT = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cEXT.fit(train_x_vectors, train_y_cEXT)\n",
    "evaluation.append([data, vec_name, name, \"cEXT\", clf_svm_cEXT.score(test_x_vectors, test_y_cEXT)])\n",
    "print(\"cEXT score: \", clf_svm_cEXT.score(test_x_vectors, test_y_cEXT))\n",
    "\n",
    "try:\n",
    "    print(\"training Neuroticism cNEU using SVM...\")\n",
    "    clf_svm_cNEU = svm.SVC(kernel='linear', C=1000, gamma=0.001)\n",
    "    clf_svm_cNEU.fit(train_x_vectors, train_y_cNEU)\n",
    "    evaluation.append([data, vec_name, name, \"cNEU\", clf_svm_cNEU.score(test_x_vectors, test_y_cNEU)])\n",
    "    print(\"cNEU score: \", clf_svm_cNEU.score(test_x_vectors, test_y_cNEU))\n",
    "except:\n",
    "    print(\"with this data not available (MBTI only 4 dimensions)\")\n",
    "\n",
    "print(\"training Agreeableness cAGR using using SVM...\")\n",
    "clf_svm_cAGR = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cAGR.fit(train_x_vectors, train_y_cAGR)\n",
    "evaluation.append([data, vec_name, name, \"cAGR\", clf_svm_cAGR.score(test_x_vectors, test_y_cAGR)])\n",
    "print(\"cAGR score: \", clf_svm_cAGR.score(test_x_vectors, test_y_cAGR))\n",
    "\n",
    "print(\"training Conscientiousness cCON using SVM...\")\n",
    "clf_svm_cCON = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cCON.fit(train_x_vectors, train_y_cCON)\n",
    "evaluation.append([data, vec_name, name, \"cCON\", clf_svm_cCON.score(test_x_vectors, test_y_cCON)])\n",
    "print(\"cCON score: \", clf_svm_cCON.score(test_x_vectors, test_y_cCON))\n",
    "\n",
    "print(\"training Openness to Experience cOPN using SVM...\")\n",
    "clf_svm_cOPN = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cOPN.fit(train_x_vectors, train_y_cOPN)\n",
    "evaluation.append([data, vec_name, name, \"cOPN\", clf_svm_cOPN.score(test_x_vectors, test_y_cOPN)])\n",
    "print(\"cOPN score: \", clf_svm_cOPN.score(test_x_vectors, test_y_cOPN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82473a0",
   "metadata": {
    "id": "c82473a0"
   },
   "outputs": [],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2dbd88b",
   "metadata": {
    "id": "a2dbd88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Extraversion cEXT using SVM...\n",
      "cEXT score:  0.7747868999551368\n",
      "training Neuroticism cNEU using SVM...\n",
      "with this data not available (MBTI only 4 dimensions)\n",
      "training Agreeableness cAGR using using SVM...\n",
      "cAGR score:  0.7662628981606101\n",
      "training Conscientiousness cCON using SVM...\n",
      "cCON score:  0.7146702557200538\n",
      "training Openness to Experience cOPN using SVM...\n",
      "cOPN score:  0.8129205921938089\n"
     ]
    }
   ],
   "source": [
    "### SVM - TFIDF\n",
    "\n",
    "print(\"training Extraversion cEXT using SVM...\")\n",
    "clf_svm_cEXT = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cEXT.fit(train_x_vectors_tf, train_y_cEXT)\n",
    "evaluation_tf.append([data, vec_name, name, \"cEXT\", clf_svm_cEXT.score(test_x_vectors_tf, test_y_cEXT)])\n",
    "print(\"cEXT score: \", clf_svm_cEXT.score(test_x_vectors_tf, test_y_cEXT))\n",
    "\n",
    "try:\n",
    "    print(\"training Neuroticism cNEU using SVM...\")\n",
    "    clf_svm_cNEU = svm.SVC(kernel='linear')\n",
    "    clf_svm_cNEU.fit(train_x_vectors_tf, train_y_cNEU)\n",
    "    evaluation_tf.append([data, vec_name, name, \"cNEU\", clf_svm_cNEU.score(test_x_vectors_tf, test_y_cNEU)])\n",
    "    print(\"cNEU score: \", clf_svm_cNEU.score(test_x_vectors_tf, test_y_cNEU))\n",
    "except:\n",
    "    print(\"with this data not available (MBTI only 4 dimensions)\")\n",
    "\n",
    "print(\"training Agreeableness cAGR using using SVM...\")\n",
    "clf_svm_cAGR = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cAGR.fit(train_x_vectors_tf, train_y_cAGR)\n",
    "evaluation_tf.append([data, vec_name, name, \"cAGR\", clf_svm_cAGR.score(test_x_vectors_tf, test_y_cAGR)])\n",
    "print(\"cAGR score: \", clf_svm_cAGR.score(test_x_vectors_tf, test_y_cAGR))\n",
    "\n",
    "print(\"training Conscientiousness cCON using SVM...\")\n",
    "clf_svm_cCON = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cCON.fit(train_x_vectors_tf, train_y_cCON)\n",
    "evaluation_tf.append([data, vec_name, name, \"cCON\", clf_svm_cCON.score(test_x_vectors_tf, test_y_cCON)])\n",
    "print(\"cCON score: \", clf_svm_cCON.score(test_x_vectors_tf, test_y_cCON))\n",
    "\n",
    "print(\"training Openness to Experience cOPN using SVM...\")\n",
    "clf_svm_cOPN = svm.SVC(C=1000, gamma=0.001)\n",
    "clf_svm_cOPN.fit(train_x_vectors_tf, train_y_cOPN)\n",
    "evaluation_tf.append([data, vec_name, name, \"cOPN\", clf_svm_cOPN.score(test_x_vectors_tf, test_y_cOPN)])\n",
    "print(\"cOPN score: \", clf_svm_cOPN.score(test_x_vectors_tf, test_y_cOPN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd218095",
   "metadata": {
    "id": "fd218095"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_grid = {'C':[100,1000], 'gamma':[0.001,0.0001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9d5c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = RandomizedSearchCV(SVC(), random_grid, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ed25d819",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Piyush\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV] END .................................C=100, gamma=0.001; total time= 2.6min\n",
      "[CV] END .................................C=100, gamma=0.001; total time= 2.7min\n",
      "[CV] END .................................C=100, gamma=0.001; total time= 2.3min\n",
      "[CV] END .................................C=100, gamma=0.001; total time= 2.6min\n",
      "[CV] END .................................C=100, gamma=0.001; total time= 2.6min\n",
      "[CV] END ................................C=100, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ................................C=100, gamma=0.0001; total time= 2.6min\n",
      "[CV] END ................................C=100, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ................................C=100, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ................................C=100, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ................................C=1000, gamma=0.001; total time= 3.3min\n",
      "[CV] END ................................C=1000, gamma=0.001; total time= 3.2min\n",
      "[CV] END ................................C=1000, gamma=0.001; total time= 3.2min\n",
      "[CV] END ................................C=1000, gamma=0.001; total time= 2.7min\n",
      "[CV] END ................................C=1000, gamma=0.001; total time= 3.3min\n",
      "[CV] END ...............................C=1000, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ...............................C=1000, gamma=0.0001; total time= 2.8min\n",
      "[CV] END ...............................C=1000, gamma=0.0001; total time= 3.0min\n",
      "[CV] END ...............................C=1000, gamma=0.0001; total time= 2.7min\n",
      "[CV] END ...............................C=1000, gamma=0.0001; total time= 2.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=SVC(),\n",
       "                   param_distributions={'C': [100, 1000],\n",
       "                                        'gamma': [0.001, 0.0001]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(train_x_vectors_tf, train_y_cEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5c4fc0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.001, 'C': 1000}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01eb386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, gamma=0.001)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d9b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter New.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
